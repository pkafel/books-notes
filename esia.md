# Event Streams in Action (by Alexander Dean)

## Chapter 1

**Event** - thing that can be tied to a specific point in time (start of Black Friday, crash of an application etc).

**Continuous event stream** - is an unterminated succession of individual events, ordered by the point in time at which each event occurred.

### Data processing splitted by eras:
* classic era - businesses operated a disparate set of on-premise systems, feeding into a data warehouse. These systems featured high data latency, heavily silo’ed data and many point-to-point connections between systems.
* hybrid era - businesses operate a hotchpotch of different transactional and analytics systems. There are disparate data silos, but also attempts at “log everything” approaches with Hadoop and/or systems monitoring.
* unified era (future) - businesses restructure around an append-only log to which we write all events generated by our applications; software systems should communicate with each other in an decoupled way through the unified log.

## Chapter 2

**Unified log** - append-only, ordered, distributed log. Good example of open source unified log is [Apache Kafka](https://kafka.apache.org/). Example of how to use it with some command-line tools can be find [here](https://gist.github.com/pkafel/7cca260427532bf64c58407964c623d2).

## Chapter 3

**Complex Event Processing (CEP)** - CEP emphasizes the derivation of “complex events” from simpler input events and pre-dates unified log technologies like Apache Kafka, and so CEP systems will tend to work on much smaller (and potentially unordered) event streams.

### Two types of stream processing:
* single event processing
* multiple event processing
